{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mNQu7ar_KDqW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 초기 셋팅"
      ],
      "metadata": {
        "id": "ssNfX5OYEpoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "\"\"\"\n",
        "DeepSNAP는 그래프 신경망(Graph Neural Networks)을 구축하고 훈련하기 위한 파이썬 패키지\n",
        "DeepSNAP은 PyTorch 기반의 그래프 신경망 라이브러리 PyG(PyTorch Geometric)에서 영감을 받아 개발되었다. DeepSNAP은 PyG와 유사한 인터페이스를 제공하여 그래프 데이터를 로드하고 전처리할 수 있다.\n",
        "\"\"\"\n",
        "!pip install -U -q PyDrive\n",
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)\n",
        "if use_cuda:\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# Install required packages.\n",
        "# !pip install torch-sparse\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim, Tensor\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj\n",
        "#-- import required modules Blog\n",
        "\n",
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "rating_path = '/content/ml-latest-small/ratings.csv'\n",
        "item_path = \"/content/ml-latest-small/movies.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwaaUaTTEZMN",
        "outputId": "391b79ac-4e3a-4ec9-9453-157d591c0c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "cpu\n",
            "False\n",
            "2.1.0+cu118\n",
            "11.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_size = 30\n",
        "# def MF_data(path, data_frame, rating_threshold = 5, excluded_user =None):\n",
        "\n",
        "def blog_LightGCN_data(path, data_frame, rating_threshold =5, excluded_user=None):\n",
        "\n",
        "  #-- 유저, 아이템 매핑\n",
        "  rating_data = pd.read_csv(path[0], index_col= data_frame[0])\n",
        "  item_data = pd.read_csv(path[1], index_col= data_frame[1])\n",
        "  data = pd.read_csv(path[0])\n",
        "\n",
        "\n",
        "  #-- 테스트를 위한 특정 유저의 가장 앞에 있는 데이터 삭제\n",
        "\n",
        "  if excluded_user is not None:\n",
        "    print(\"{}번째 유저 {}이상 데이터 삭제하기 전\".format(excluded_user, rating_threshold))\n",
        "    excluded_user_data = data[data[data_frame[0]] == excluded_user]\n",
        "    print(excluded_user_data.head(10))\n",
        "\n",
        "    user_data = data[data[data_frame[0]] == excluded_user]\n",
        "    user_data_5stars = user_data[user_data[data_frame[2]] >= rating_threshold]  # Filter the data with a rating of 5.0r_user_data[r_user_data[data_frame[2]] == 5.0]  # Filter the data with a rating of 5.0\n",
        "\n",
        "    r_user_data =  rating_data[rating_data.index == excluded_user].reset_index()\n",
        "\n",
        "    if not user_data_5stars.empty:\n",
        "      excluded_number = remove_size\n",
        "      user_data_5stars = user_data_5stars.head(excluded_number)\n",
        "      r_user_data_5stars = r_user_data[r_user_data[data_frame[2]] >= rating_threshold]\n",
        "      data = data.drop(user_data_5stars.index)\n",
        "\n",
        "      row_index = []\n",
        "      for i in range(0,excluded_number):\n",
        "        row_index.append(r_user_data_5stars.iloc[i].name)\n",
        "\n",
        "      rating_data = rating_data.reset_index().drop(row_index[0])\n",
        "      rating_data.set_index(data_frame[0], inplace=True)\n",
        "      for i in range(1, len(row_index)) :\n",
        "        rating_data = rating_data.reset_index().drop(row_index[i]-i)\n",
        "      # rating_data = rating_data.drop(rating_data.iloc.nam)\n",
        "        rating_data.set_index(data_frame[0], inplace=True)\n",
        "\n",
        "    excluded_user_data = data[data[data_frame[0]] == excluded_user]\n",
        "    print(\"\\n\\n\\n{}번째 유저 {} 이상 데이터 삭제하기 후\".format(excluded_user, rating_threshold))\n",
        "    print(excluded_user_data.head(10))\n",
        "\n",
        "  # # rating_data의 컬럼 확인\n",
        "  # print(rating_data.head(5))\n",
        "\n",
        "  user_mapping = {index: i for i, index in enumerate(rating_data.index.unique())}\n",
        "  item_mapping = {index: i for i, index in enumerate(item_data.index.unique())}\n",
        "\n",
        "  #-- 매핑 데이터로 edge연결\n",
        "  edge_index = None\n",
        "  src = [user_mapping[index] for index in data[data_frame[0]]]\n",
        "  dst = [item_mapping[index] for index in data[data_frame[1]]]\n",
        "  edge_attr = torch.from_numpy(data[data_frame[2]].values).view(-1, 1).to(torch.long) >= 3.5\n",
        "\n",
        "  edge_index = [[], []]\n",
        "  for i in range(edge_attr.shape[0]):\n",
        "    if edge_attr[i]:\n",
        "        edge_index[0].append(src[i])\n",
        "        edge_index[1].append(dst[i])\n",
        "  edge_index = torch.tensor(edge_index)\n",
        "\n",
        "  #-- 데이터 분할 8:1:1\n",
        "  num_users, num_movies = len(user_mapping), len(item_mapping)\n",
        "  num_interactions = edge_index.shape[1]\n",
        "  all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "  train_indices, test_indices = train_test_split(\n",
        "      all_indices, test_size=0.2, random_state=1)\n",
        "  val_indices, test_indices = train_test_split(\n",
        "      test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "  train_edge_index = edge_index[:, train_indices]\n",
        "  val_edge_index = edge_index[:, val_indices]\n",
        "  test_edge_index = edge_index[:, test_indices]\n",
        "\n",
        "  print(\"Train Edge Data : \", train_edge_index.shape)\n",
        "  print(\"Val Edge Data :\", val_edge_index.shape)\n",
        "  print(\"Test Edge Data : \", test_edge_index.shape)\n",
        "\n",
        "  #-- 연결된 엣지를 희소행렬로 변환\n",
        "  # convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "  from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "  train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "      num_users + num_movies, num_users + num_movies))\n",
        "  val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "      num_users + num_movies, num_users + num_movies))\n",
        "  test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "      num_users + num_movies, num_users + num_movies))\n",
        "\n",
        "  tet_edge_data = [edge_index, train_edge_index, val_edge_index, test_edge_index]\n",
        "  tet_sparse_data = [train_sparse_edge_index, val_sparse_edge_index, test_sparse_edge_index]\n",
        "  return tet_edge_data, tet_sparse_data, user_mapping, item_mapping\n",
        "#-- Blog --"
      ],
      "metadata": {
        "id": "FWvy7WZfEjqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excluded_user_id = 50\n",
        "data_frame = [\"userId\", \"movieId\", \"rating\"]\n",
        "path = [rating_path, item_path]\n",
        "rating_threshold = 4\n",
        "\n",
        "blog_tet_edge_data, blog_tet_sparse_data, user_mapping, item_mapping = blog_LightGCN_data(path, data_frame, rating_threshold, excluded_user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDiSo12EoTe",
        "outputId": "491b4d18-6c9b-4dd8-ecb1-e2ad74928214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50번째 유저 4이상 데이터 삭제하기 전\n",
            "      userId  movieId  rating   timestamp\n",
            "7112      50        1     3.0  1514238116\n",
            "7113      50       32     3.0  1523740563\n",
            "7114      50      111     4.0  1534178790\n",
            "7115      50      165     3.0  1514238058\n",
            "7116      50      296     4.0  1500573696\n",
            "7117      50      318     3.5  1514237959\n",
            "7118      50      356     3.0  1514238146\n",
            "7119      50      541     4.0  1514238015\n",
            "7120      50      593     3.5  1514237974\n",
            "7121      50      596     2.0  1514238575\n",
            "\n",
            "\n",
            "\n",
            "50번째 유저 4 이상 데이터 삭제하기 후\n",
            "      userId  movieId  rating   timestamp\n",
            "7112      50        1     3.0  1514238116\n",
            "7113      50       32     3.0  1523740563\n",
            "7115      50      165     3.0  1514238058\n",
            "7117      50      318     3.5  1514237959\n",
            "7118      50      356     3.0  1514238146\n",
            "7120      50      593     3.5  1514237974\n",
            "7121      50      596     2.0  1514238575\n",
            "7123      50      741     3.5  1515105957\n",
            "7125      50      783     2.5  1514238681\n",
            "7126      50      837     2.5  1514239044\n",
            "Train Edge Data :  torch.Size([2, 38840])\n",
            "Val Edge Data : torch.Size([2, 4855])\n",
            "Test Edge Data :  torch.Size([2, 4855])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MF모델 정의"
      ],
      "metadata": {
        "id": "kLNulnmHEtSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 테스트용"
      ],
      "metadata": {
        "id": "cEjETlZ2Y9Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = blog_tet_edge_data[0][0].max().item()+1\n",
        "num_items = blog_tet_edge_data[0][1].max().item()+1\n",
        "embedding_dim = 32\n",
        "\n",
        "user_indices = blog_tet_edge_data[1][0]\n",
        "item_indices = blog_tet_edge_data[1][1]\n",
        "\n",
        "mf_user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
        "mf_item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "\n",
        "nn.init.normal_(mf_user_embeddings.weight, std=0.1)\n",
        "nn.init.normal_(mf_item_embeddings.weight, std=0.1)\n",
        "\n",
        "print(mf_user_embeddings)\n",
        "print(mf_item_embeddings)\n",
        "\n",
        "print(\"user_indices size is \",user_indices.size()) #-- 38840 -> 유저-아이템 상호작용 횟수\n",
        "print(\"item_indices size is \",item_indices.size()) #-- 38840 -> 유저-아이템 상호작용 횟수\n",
        "\n",
        "#-- 처음 eu 임베딩값은 (610, 32)\n",
        "#-- 처음 ei 임베딩값은 (9742, 32)\n",
        "mf_user_embedding = mf_user_embeddings(user_indices)\n",
        "mf_item_embedding = mf_item_embeddings(item_indices)\n",
        "#-- 유저-아이템 상호작용 기반으로 유저 임베딩 아이템 임베딩\n",
        "\n",
        "print(\"user_embedding size is {}\".format(mf_user_embedding.size())) #-- [38840, 32]\n",
        "print(\"item_embedding size is {}\".format(mf_item_embedding.size())) #-- [38840, 32]\n",
        "\n",
        "\n",
        "predictions = (mf_user_embedding * mf_item_embedding).sum(1) #-- 38840 1차원으로\n",
        "print(\"predictions size is \",predictions.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2kBX-LNbyhy",
        "outputId": "323ec917-c198-45b6-cd9a-6fce11dd269d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(610, 32)\n",
            "Embedding(9742, 32)\n",
            "user_indices size is  torch.Size([38840])\n",
            "item_indices size is  torch.Size([38840])\n",
            "user_embedding size is torch.Size([38840, 32])\n",
            "item_embedding size is torch.Size([38840, 32])\n",
            "predictions size is  torch.Size([38840])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MFGCN"
      ],
      "metadata": {
        "id": "UaY8zjJbY_VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MFGCN(MessagePassing):\n",
        "      def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "          super().__init__()\n",
        "          self.num_users, self.num_items = num_users, num_items\n",
        "          self.embedding_dim, self.K = embedding_dim, K\n",
        "          self.add_self_loops = add_self_loops\n",
        "          self.users_emb = nn.Embedding(\n",
        "              num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "          self.items_emb = nn.Embedding(\n",
        "              num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "          nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "          nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "\n",
        "          self.mf_user_embedding = self.users_emb\n",
        "          self.mf_item_embedding = self.items_emb\n",
        "      def forward(self, edge_index: SparseTensor):\n",
        "          # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "          edge_index_norm = gcn_norm(\n",
        "              edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "          # print(self.users_emb) #-- Embedding(610, 32)\n",
        "          # print(self.items_emb) #-- Embedding(9742, 32)\n",
        "\n",
        "          #-- MF 기법 --#\n",
        "          # mf_user_embedding = self.users_emb\n",
        "          # mf_item_embedding = self.items_emb\n",
        "          # print(\"mf_user\", mf_user_embedding)\n",
        "          # print(\"mf_item_embedding\", mf_item_embedding)\n",
        "          row, col, _ = edge_index_norm.coo()\n",
        "          user_indices = row\n",
        "          item_indices = col\n",
        "          # print(\"user_indices size is \",user_indices.size()) #-- 38840 -> 유저-아이템 상호작용 횟수\n",
        "          # print(\"item_indices size is \",item_indices.size()) #-- 38840 -> 유저-아이템 상호작용 횟수\n",
        "          mf_user_embedding = self.users_emb(user_indices)\n",
        "          mf_item_embedding = self.items_emb(item_indices)\n",
        "\n",
        "          user_avg_emb = torch.zeros(self.num_users, self.embedding_dim).to(self.users_emb.weight.device)\n",
        "          item_avg_emb = torch.zeros(self.num_items, self.embedding_dim).to(self.items_emb.weight.device)\n",
        "\n",
        "          user_counts = torch.bincount(user_indices, minlength=self.num_users).float().clamp(min=1) # 최소 1로 설정하여 0으로 나누는 것을 방지\n",
        "          item_counts = torch.bincount(item_indices, minlength=self.num_items).float().clamp(min=1)\n",
        "\n",
        "          user_avg_emb.index_add_(0, user_indices, mf_user_embedding)\n",
        "          item_avg_emb.index_add_(0, item_indices, mf_item_embedding)\n",
        "\n",
        "          user_avg_emb /= user_counts.unsqueeze(-1)\n",
        "          item_avg_emb /= item_counts.unsqueeze(-1)\n",
        "\n",
        "          # predictions = (mf_user_embedding * mf_item_embedding).sum(1)\n",
        "          # --predictions size is  torch.Size([38840])\n",
        "          # print(predictions.size())\n",
        "\n",
        "          # print(\"user_embedding size is {}\".format(mf_user_embedding.size())) #-- [38840, 32]\n",
        "          # print(\"item_embedding size is {}\".format(mf_item_embedding.size())) #-- [38840, 32]\n",
        "          #-- MF 기법 --#\n",
        "\n",
        "          #== LightGCN ==#\n",
        "          emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "          embs = [emb_0]\n",
        "          emb_k = emb_0\n",
        "          # print(\"emb_0\", emb_0.size()) #-- 610 + 9742 => [10352, 32]\n",
        "\n",
        "          # multi-scale diffusion\n",
        "          for i in range(self.K):\n",
        "              emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "              # print(\"emb_k\", emb_k.size()) #-- 610 + 9742 => [10352, 32]\n",
        "              embs.append(emb_k)\n",
        "          embs = torch.stack(embs, dim=1)\n",
        "\n",
        "          # print(\"embs\", embs.size()) #-- [10352, 4, 32] k만큼 추가\n",
        "\n",
        "          emb_final = torch.mean(embs, dim=1) # E^K 10352, 32\n",
        "          # print(\"emb_final is \", emb_final.size())\n",
        "\n",
        "          users_emb_final, items_emb_final = torch.split(\n",
        "              emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "          # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "          # print(\"users_emb_final is \", users_emb_final.size())\n",
        "          # print(\"items_emb_final is \", items_emb_final.size())\n",
        "          #== LightGCN ==#\n",
        "\n",
        "\n",
        "          # combined_users_emb = mf_user_embedding[user_indices] + users_emb_final[user_indices]\n",
        "          # combined_items_emb = mf_item_embedding[item_indices] + items_emb_final[item_indices]\n",
        "          combined_users_emb = user_avg_emb + users_emb_final\n",
        "          combined_items_emb = item_avg_emb + items_emb_final\n",
        "          # print(\"combined_users_emb\",combined_users_emb.size())\n",
        "          # print(\"combined_items_emb\",combined_items_emb.size())\n",
        "\n",
        "          # 결합된 임베딩 정규화 (옵션)\n",
        "          # combined_users_emb /= 2.0\n",
        "          # combined_items_emb /= 2.0\n",
        "          # e_u^K, e_u^0, e_i^K, e_i^0 형태로 임베딩 반환\n",
        "          return combined_users_emb, self.users_emb.weight, combined_items_emb, self.items_emb.weight\n",
        "\n",
        "          # return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "      def message(self, x_j: Tensor) -> Tensor:\n",
        "          return x_j\n",
        "\n",
        "      def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "          # computes \\tilde{A} @ x\n",
        "          return matmul(adj_t, x)"
      ],
      "metadata": {
        "id": "UI12a0PCvBfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_model = MFGCN(len(user_mapping), len(item_mapping), embedding_dim= 32)\n",
        "# model = model.to(device)\n",
        "# model.train()\n",
        "# LR = 1e-4\n",
        "# optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "# edge_index = blog_tet_edge_data[0].to(device)\n",
        "# train_edge_index = blog_tet_edge_data[1].to(device)\n",
        "# train_sparse_edge_index = blog_tet_sparse_data[0].to(device)\n",
        "\n",
        "\n",
        "# val_edge_index = blog_tet_edge_data[2].to(device)\n",
        "# val_sparse_edge_index = blog_tet_sparse_data[1].to(device)\n",
        "\n",
        "# users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "#           train_sparse_edge_index)\n"
      ],
      "metadata": {
        "id": "3hGYtuZrvNKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습"
      ],
      "metadata": {
        "id": "mNQu7ar_KDqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-- 손실함수 bpr\n",
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "    return loss\n",
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices\n",
        "\n",
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items\n",
        "\n",
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()\n",
        "\n",
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()\n",
        "\n",
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg\n",
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg\n",
        "def blog_fit(model, blog_tet_edge_data, blog_tet_sparse_data, epochs = 50):\n",
        "  # define contants\n",
        "  ITERATIONS = epochs\n",
        "  BATCH_SIZE = 2048\n",
        "  LR = 1e-3\n",
        "  ITERS_PER_EVAL = 300\n",
        "  ITERS_PER_LR_DECAY = 300\n",
        "  K = 10\n",
        "  LAMBDA = 1e-6\n",
        "\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "  scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "  edge_index = blog_tet_edge_data[0].to(device)\n",
        "  train_edge_index = blog_tet_edge_data[1].to(device)\n",
        "  train_sparse_edge_index = blog_tet_sparse_data[0].to(device)\n",
        "\n",
        "  val_edge_index = blog_tet_edge_data[2].to(device)\n",
        "  val_sparse_edge_index = blog_tet_sparse_data[1].to(device)\n",
        "\n",
        "  # training loop\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  for iter in range(ITERATIONS):\n",
        "      # forward propagation\n",
        "      users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "          train_sparse_edge_index)\n",
        "\n",
        "      # mini batching\n",
        "      user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "          BATCH_SIZE, train_edge_index)\n",
        "      user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "          device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "      users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "      pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "          pos_item_indices], items_emb_0[pos_item_indices]\n",
        "      neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "          neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "      # loss computation\n",
        "      train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                            pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if iter % ITERS_PER_EVAL == 0:\n",
        "          model.eval()\n",
        "          val_loss, recall, precision, ndcg = evaluation(\n",
        "              model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "          print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "          train_losses.append(train_loss.item())\n",
        "          val_losses.append(val_loss)\n",
        "          model.train()\n",
        "\n",
        "      if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "          scheduler.step()\n",
        "  iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "  plt.plot(iters, train_losses, label='train')\n",
        "  plt.plot(iters, val_losses, label='validation')\n",
        "  plt.xlabel('iteration')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('training and validation loss curves')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "p3dErS5wIhph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 확인"
      ],
      "metadata": {
        "id": "1ErFWeGqKFJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blog_fit(blog_model, blog_tet_edge_data, blog_tet_sparse_data, epochs =20000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g5Hc0CpYIoUW",
        "outputId": "e0674b48-179c-4c5c-82b7-961773ee12c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/20000] train_loss: -1.46415, val_loss: -1.24316, val_recall@10: 0.07699, val_precision@10: 0.04973, val_ndcg@10: 0.0715\n",
            "[Iteration 300/20000] train_loss: -7.9834, val_loss: -6.69342, val_recall@10: 0.08248, val_precision@10: 0.05385, val_ndcg@10: 0.07929\n",
            "[Iteration 600/20000] train_loss: -25.82973, val_loss: -21.76326, val_recall@10: 0.07912, val_precision@10: 0.05331, val_ndcg@10: 0.08168\n",
            "[Iteration 900/20000] train_loss: -54.5865, val_loss: -45.71547, val_recall@10: 0.07907, val_precision@10: 0.05385, val_ndcg@10: 0.08233\n",
            "[Iteration 1200/20000] train_loss: -88.74312, val_loss: -75.34441, val_recall@10: 0.08085, val_precision@10: 0.0542, val_ndcg@10: 0.08393\n",
            "[Iteration 1500/20000] train_loss: -130.06308, val_loss: -109.89406, val_recall@10: 0.08043, val_precision@10: 0.05492, val_ndcg@10: 0.08426\n",
            "[Iteration 1800/20000] train_loss: -174.10085, val_loss: -147.38057, val_recall@10: 0.0803, val_precision@10: 0.0551, val_ndcg@10: 0.08478\n",
            "[Iteration 2100/20000] train_loss: -220.11588, val_loss: -186.21646, val_recall@10: 0.08144, val_precision@10: 0.05528, val_ndcg@10: 0.08525\n",
            "[Iteration 2400/20000] train_loss: -260.40536, val_loss: -227.12592, val_recall@10: 0.08679, val_precision@10: 0.05617, val_ndcg@10: 0.08721\n",
            "[Iteration 2700/20000] train_loss: -315.63983, val_loss: -269.57724, val_recall@10: 0.0842, val_precision@10: 0.05564, val_ndcg@10: 0.08645\n",
            "[Iteration 3000/20000] train_loss: -357.56995, val_loss: -309.02942, val_recall@10: 0.08223, val_precision@10: 0.05564, val_ndcg@10: 0.08619\n",
            "[Iteration 3300/20000] train_loss: -411.44968, val_loss: -346.64972, val_recall@10: 0.08524, val_precision@10: 0.05617, val_ndcg@10: 0.08724\n",
            "[Iteration 3600/20000] train_loss: -463.74203, val_loss: -393.47009, val_recall@10: 0.08472, val_precision@10: 0.05617, val_ndcg@10: 0.08709\n",
            "[Iteration 3900/20000] train_loss: -516.34747, val_loss: -430.46802, val_recall@10: 0.08223, val_precision@10: 0.05564, val_ndcg@10: 0.08615\n",
            "[Iteration 4200/20000] train_loss: -550.14044, val_loss: -466.43124, val_recall@10: 0.08525, val_precision@10: 0.05653, val_ndcg@10: 0.08748\n",
            "[Iteration 4500/20000] train_loss: -613.7005, val_loss: -507.83768, val_recall@10: 0.08486, val_precision@10: 0.05617, val_ndcg@10: 0.08742\n",
            "[Iteration 4800/20000] train_loss: -663.27362, val_loss: -546.73511, val_recall@10: 0.08544, val_precision@10: 0.05617, val_ndcg@10: 0.08764\n",
            "[Iteration 5100/20000] train_loss: -706.07452, val_loss: -581.04205, val_recall@10: 0.08536, val_precision@10: 0.05599, val_ndcg@10: 0.08751\n",
            "[Iteration 5400/20000] train_loss: -751.3136, val_loss: -612.27887, val_recall@10: 0.08577, val_precision@10: 0.05617, val_ndcg@10: 0.08788\n",
            "[Iteration 5700/20000] train_loss: -769.69696, val_loss: -649.51685, val_recall@10: 0.08531, val_precision@10: 0.05564, val_ndcg@10: 0.08753\n",
            "[Iteration 6000/20000] train_loss: -824.18073, val_loss: -683.88916, val_recall@10: 0.08533, val_precision@10: 0.05599, val_ndcg@10: 0.08772\n",
            "[Iteration 6300/20000] train_loss: -847.24927, val_loss: -716.60803, val_recall@10: 0.08553, val_precision@10: 0.05599, val_ndcg@10: 0.08784\n",
            "[Iteration 6600/20000] train_loss: -874.46265, val_loss: -742.07471, val_recall@10: 0.08561, val_precision@10: 0.05581, val_ndcg@10: 0.08777\n",
            "[Iteration 6900/20000] train_loss: -951.61005, val_loss: -766.82977, val_recall@10: 0.0871, val_precision@10: 0.05581, val_ndcg@10: 0.08816\n",
            "[Iteration 7200/20000] train_loss: -950.95093, val_loss: -797.8125, val_recall@10: 0.08662, val_precision@10: 0.05564, val_ndcg@10: 0.08795\n",
            "[Iteration 7500/20000] train_loss: -961.76099, val_loss: -826.08459, val_recall@10: 0.0871, val_precision@10: 0.05581, val_ndcg@10: 0.08818\n",
            "[Iteration 7800/20000] train_loss: -1013.26611, val_loss: -863.12207, val_recall@10: 0.08709, val_precision@10: 0.05617, val_ndcg@10: 0.08832\n",
            "[Iteration 8100/20000] train_loss: -1054.21033, val_loss: -883.19904, val_recall@10: 0.08709, val_precision@10: 0.05617, val_ndcg@10: 0.08829\n",
            "[Iteration 8400/20000] train_loss: -1068.95935, val_loss: -904.68597, val_recall@10: 0.08704, val_precision@10: 0.05617, val_ndcg@10: 0.0883\n",
            "[Iteration 8700/20000] train_loss: -1099.95593, val_loss: -930.37433, val_recall@10: 0.08732, val_precision@10: 0.05653, val_ndcg@10: 0.08851\n",
            "[Iteration 9000/20000] train_loss: -1150.69824, val_loss: -956.5896, val_recall@10: 0.08776, val_precision@10: 0.05635, val_ndcg@10: 0.08858\n",
            "[Iteration 9300/20000] train_loss: -1171.87891, val_loss: -979.50055, val_recall@10: 0.08764, val_precision@10: 0.05617, val_ndcg@10: 0.08846\n",
            "[Iteration 9600/20000] train_loss: -1208.12402, val_loss: -983.39532, val_recall@10: 0.08753, val_precision@10: 0.05599, val_ndcg@10: 0.08835\n",
            "[Iteration 9900/20000] train_loss: -1213.96118, val_loss: -1009.06744, val_recall@10: 0.08735, val_precision@10: 0.05581, val_ndcg@10: 0.08823\n",
            "[Iteration 10200/20000] train_loss: -1246.39368, val_loss: -1027.4231, val_recall@10: 0.08693, val_precision@10: 0.05581, val_ndcg@10: 0.08814\n",
            "[Iteration 10500/20000] train_loss: -1275.48535, val_loss: -1051.75415, val_recall@10: 0.08694, val_precision@10: 0.05581, val_ndcg@10: 0.08798\n",
            "[Iteration 10800/20000] train_loss: -1299.59058, val_loss: -1076.19727, val_recall@10: 0.08704, val_precision@10: 0.05599, val_ndcg@10: 0.08818\n",
            "[Iteration 11100/20000] train_loss: -1324.77454, val_loss: -1071.82458, val_recall@10: 0.08694, val_precision@10: 0.05581, val_ndcg@10: 0.08814\n",
            "[Iteration 11400/20000] train_loss: -1277.18628, val_loss: -1102.74146, val_recall@10: 0.08682, val_precision@10: 0.05564, val_ndcg@10: 0.08795\n",
            "[Iteration 11700/20000] train_loss: -1330.35913, val_loss: -1113.24609, val_recall@10: 0.08759, val_precision@10: 0.05617, val_ndcg@10: 0.08846\n",
            "[Iteration 12000/20000] train_loss: -1342.19275, val_loss: -1120.33496, val_recall@10: 0.08699, val_precision@10: 0.05599, val_ndcg@10: 0.08819\n",
            "[Iteration 12300/20000] train_loss: -1357.28796, val_loss: -1141.55481, val_recall@10: 0.08754, val_precision@10: 0.05599, val_ndcg@10: 0.08833\n",
            "[Iteration 12600/20000] train_loss: -1384.34155, val_loss: -1163.97046, val_recall@10: 0.08658, val_precision@10: 0.05564, val_ndcg@10: 0.08788\n",
            "[Iteration 12900/20000] train_loss: -1371.5708, val_loss: -1161.62646, val_recall@10: 0.08694, val_precision@10: 0.05581, val_ndcg@10: 0.08807\n",
            "[Iteration 13200/20000] train_loss: -1386.7865, val_loss: -1181.78223, val_recall@10: 0.08658, val_precision@10: 0.05564, val_ndcg@10: 0.0879\n",
            "[Iteration 13500/20000] train_loss: -1422.84961, val_loss: -1202.37903, val_recall@10: 0.08647, val_precision@10: 0.05564, val_ndcg@10: 0.08791\n",
            "[Iteration 13800/20000] train_loss: -1423.51294, val_loss: -1196.14868, val_recall@10: 0.08659, val_precision@10: 0.05581, val_ndcg@10: 0.08799\n",
            "[Iteration 14100/20000] train_loss: -1450.75476, val_loss: -1203.75098, val_recall@10: 0.08599, val_precision@10: 0.05564, val_ndcg@10: 0.08784\n",
            "[Iteration 14400/20000] train_loss: -1467.40771, val_loss: -1223.74414, val_recall@10: 0.08599, val_precision@10: 0.05564, val_ndcg@10: 0.08781\n",
            "[Iteration 14700/20000] train_loss: -1460.16248, val_loss: -1237.15161, val_recall@10: 0.08594, val_precision@10: 0.05546, val_ndcg@10: 0.08765\n",
            "[Iteration 15000/20000] train_loss: -1474.73987, val_loss: -1235.68835, val_recall@10: 0.08597, val_precision@10: 0.05564, val_ndcg@10: 0.08781\n",
            "[Iteration 15300/20000] train_loss: -1476.79626, val_loss: -1232.83044, val_recall@10: 0.08597, val_precision@10: 0.05564, val_ndcg@10: 0.0878\n",
            "[Iteration 15600/20000] train_loss: -1502.35669, val_loss: -1253.72046, val_recall@10: 0.08597, val_precision@10: 0.05564, val_ndcg@10: 0.0878\n",
            "[Iteration 15900/20000] train_loss: -1464.8269, val_loss: -1254.69897, val_recall@10: 0.08597, val_precision@10: 0.05564, val_ndcg@10: 0.08781\n",
            "[Iteration 16200/20000] train_loss: -1528.35156, val_loss: -1272.28455, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.0884\n",
            "[Iteration 16500/20000] train_loss: -1536.77588, val_loss: -1285.03162, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08815\n",
            "[Iteration 16800/20000] train_loss: -1510.61426, val_loss: -1275.21863, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08819\n",
            "[Iteration 17100/20000] train_loss: -1518.09265, val_loss: -1300.62573, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08811\n",
            "[Iteration 17400/20000] train_loss: -1536.08826, val_loss: -1303.00012, val_recall@10: 0.08673, val_precision@10: 0.05599, val_ndcg@10: 0.08809\n",
            "[Iteration 17700/20000] train_loss: -1520.51111, val_loss: -1293.30286, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08799\n",
            "[Iteration 18000/20000] train_loss: -1588.77576, val_loss: -1311.04614, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08804\n",
            "[Iteration 18300/20000] train_loss: -1556.91357, val_loss: -1308.64844, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08827\n",
            "[Iteration 18600/20000] train_loss: -1564.76477, val_loss: -1321.4762, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08792\n",
            "[Iteration 18900/20000] train_loss: -1579.50159, val_loss: -1320.26758, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08803\n",
            "[Iteration 19200/20000] train_loss: -1558.44409, val_loss: -1324.33142, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08825\n",
            "[Iteration 19500/20000] train_loss: -1589.77429, val_loss: -1322.94556, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08822\n",
            "[Iteration 19800/20000] train_loss: -1632.81628, val_loss: -1325.48865, val_recall@10: 0.08657, val_precision@10: 0.05581, val_ndcg@10: 0.08792\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def blog_predict(model, user_id ,TopK, path, user_mapping, item_mapping, edge_index):\n",
        "\n",
        "  df = pd.read_csv(path[1])\n",
        "  movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "  movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "  user_pos_items = get_user_positive_items(edge_index)\n",
        "  user = user_mapping[user_id]\n",
        "  e_u = model.users_emb.weight[user]\n",
        "  scores = model.items_emb.weight @ e_u\n",
        "\n",
        "  values, indices = torch.topk(scores, k=len(user_pos_items[user]) + TopK)\n",
        "\n",
        "  movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:TopK]\n",
        "  movie_ids = [list(item_mapping.keys())[list(item_mapping.values()).index(movie)] for movie in movies]\n",
        "  titles = [movieid_title[id] for id in movie_ids]\n",
        "  genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "  # print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "  # for i in range(TopK):\n",
        "  #     print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "  movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:TopK]\n",
        "  movie_ids = [list(item_mapping.keys())[list(item_mapping.values()).index(movie)] for movie in movies]\n",
        "  titles = [movieid_title[id] for id in movie_ids]\n",
        "  genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "  # print(f\"Here are some suggested movies for user {user_id}\")\n",
        "  return titles, genres"
      ],
      "metadata": {
        "id": "NP-6iPvpPqso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 1\n",
        "excluded_user = user_id\n",
        "K = 10\n",
        "rating_threshold = 4"
      ],
      "metadata": {
        "id": "Zzs_8eJ8P3J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_titles_32_5000, blog_genres_32_5000 = blog_predict(blog_model, user_id , K, path, user_mapping, item_mapping, blog_tet_edge_data[0])"
      ],
      "metadata": {
        "id": "FQcQu1fgP70G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- 내가 삭제한 데이터\n",
        "data = pd.read_csv(path[0])\n",
        "user_data = data[data[data_frame[0]] == excluded_user]\n",
        "user_data_5stars = user_data[user_data[data_frame[2]] >= rating_threshold]  # Filter the data with a rating of 5.0r_user_data[r_user_data[data_frame[2]] == 5.0]  # Filter the data with a rating of 5.0\n",
        "# print(user_data_5stars.head(10))\n",
        "data = user_data_5stars.head(30)\n",
        "moviedIds = data['movieId'].values\n",
        "\n",
        "df = pd.read_csv(path[1])\n",
        "\n",
        "titles = []\n",
        "genres = []\n",
        "for i in moviedIds:\n",
        "    title = df[df['movieId'] == i]['title']\n",
        "    genre = df[df['movieId'] == i]['genres']\n",
        "    titles.append(title)\n",
        "    genres.append(genre)\n",
        "for i in range(len(moviedIds)):\n",
        "  print(f\"title: {titles[i].values}, genres: {genres[i].values} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJPLozDeSfmB",
        "outputId": "84c19e57-10cd-4343-ba81-7c48ecd8e7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title: ['Toy Story (1995)'], genres: ['Adventure|Animation|Children|Comedy|Fantasy'] \n",
            "title: ['Grumpier Old Men (1995)'], genres: ['Comedy|Romance'] \n",
            "title: ['Heat (1995)'], genres: ['Action|Crime|Thriller'] \n",
            "title: ['Seven (a.k.a. Se7en) (1995)'], genres: ['Mystery|Thriller'] \n",
            "title: ['Usual Suspects, The (1995)'], genres: ['Crime|Mystery|Thriller'] \n",
            "title: ['Bottle Rocket (1996)'], genres: ['Adventure|Comedy|Crime|Romance'] \n",
            "title: ['Braveheart (1995)'], genres: ['Action|Drama|War'] \n",
            "title: ['Rob Roy (1995)'], genres: ['Action|Drama|Romance|War'] \n",
            "title: ['Canadian Bacon (1995)'], genres: ['Comedy|War'] \n",
            "title: ['Desperado (1995)'], genres: ['Action|Romance|Western'] \n",
            "title: ['Billy Madison (1995)'], genres: ['Comedy'] \n",
            "title: ['Dumb & Dumber (Dumb and Dumber) (1994)'], genres: ['Adventure|Comedy'] \n",
            "title: ['Ed Wood (1994)'], genres: ['Comedy|Drama'] \n",
            "title: ['Star Wars: Episode IV - A New Hope (1977)'], genres: ['Action|Adventure|Sci-Fi'] \n",
            "title: ['Tommy Boy (1995)'], genres: ['Comedy'] \n",
            "title: ['Clear and Present Danger (1994)'], genres: ['Action|Crime|Drama|Thriller'] \n",
            "title: ['Forrest Gump (1994)'], genres: ['Comedy|Drama|Romance|War'] \n",
            "title: ['Jungle Book, The (1994)'], genres: ['Adventure|Children|Romance'] \n",
            "title: ['Mask, The (1994)'], genres: ['Action|Comedy|Crime|Fantasy'] \n",
            "title: ['Dazed and Confused (1993)'], genres: ['Comedy'] \n",
            "title: ['Fugitive, The (1993)'], genres: ['Thriller'] \n",
            "title: ['Jurassic Park (1993)'], genres: ['Action|Adventure|Sci-Fi|Thriller'] \n",
            "title: [\"Schindler's List (1993)\"], genres: ['Drama|War'] \n",
            "title: ['So I Married an Axe Murderer (1993)'], genres: ['Comedy|Romance|Thriller'] \n",
            "title: ['Three Musketeers, The (1993)'], genres: ['Action|Adventure|Comedy|Romance'] \n",
            "title: ['Tombstone (1993)'], genres: ['Action|Drama|Western'] \n",
            "title: ['Dances with Wolves (1990)'], genres: ['Adventure|Drama|Western'] \n",
            "title: ['Batman (1989)'], genres: ['Action|Crime|Thriller'] \n",
            "title: ['Silence of the Lambs, The (1991)'], genres: ['Crime|Horror|Thriller'] \n",
            "title: ['Pinocchio (1940)'], genres: ['Animation|Children|Fantasy|Musical'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-- BLOG LightGCN\n",
        "for i in range(K):\n",
        "    # if any((blog_titles_32_5000[i] == title.values).all() for title in titles):\n",
        "        print(blog_titles_32_5000[i])\n",
        "print(\"==========================임베딩 사이즈 : 32, 에포크 : 5000 =============================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_0diHYfSiY1",
        "outputId": "c21a3091-2fcc-45af-fa96-05859a7d000f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shawshank Redemption, The (1994)\n",
            "Pulp Fiction (1994)\n",
            "Godfather, The (1972)\n",
            "Terminator 2: Judgment Day (1991)\n",
            "Apollo 13 (1995)\n",
            "Lord of the Rings: The Return of the King, The (2003)\n",
            "Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
            "Lord of the Rings: The Two Towers, The (2002)\n",
            "Lion King, The (1994)\n",
            "Memento (2000)\n",
            "==========================임베딩 사이즈 : 32, 에포크 : 5000 =============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGCN"
      ],
      "metadata": {
        "id": "mkBewTXLiOeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = blog_tet_edge_data[0][0].max().item()+1\n",
        "num_items = blog_tet_edge_data[0][1].max().item()+1\n",
        "edge_index = blog_tet_edge_data[0] #-- edge_index 정보가 들어있음\n",
        "\n",
        "embedding_dim = 32\n",
        "\n",
        "user_indices = blog_tet_edge_data[1][0]\n",
        "item_indices = blog_tet_edge_data[1][1]\n",
        "\n",
        "K = 3\n",
        "add_self_loops = False\n",
        "\n",
        "gcn_user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
        "gcn_item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "nn.init.normal_(gcn_user_embeddings.weight, std=0.1)\n",
        "nn.init.normal_(gcn_item_embeddings.weight, std=0.1)\n",
        "\n",
        "print(gcn_user_embeddings) #-- Embedding(610, 32)\n",
        "print(gcn_item_embeddings) #-- Embedding(9742, 32)\n",
        "\n",
        "edge_index_norm = gcn_norm(\n",
        "              edge_index, add_self_loops=False)\n",
        "\n",
        "# print(edge_index) #-- 전체 인덱스 정보\n",
        "# print(edge_index_norm[1]) #-- [0]번 인덱스 == edge_index [1]번 인덱스 == 정규화된 텐서값\n",
        "\n",
        "emb_0 = torch.cat([gcn_user_embeddings.weight, gcn_item_embeddings.weight]) # E^0\n",
        "#-- 유저와 아이템 임베딩을 합친 차원 [10352, 32]\n",
        "print(\"emb_0\", emb_0.size()) #-- 610 + 9742 => [10352, 32]\n",
        "embs = [emb_0]\n",
        "emb_k = emb_0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "t0Y3L7zkiYRW",
        "outputId": "f35a35ca-07b6-4370-899b-a5d156ba6e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(610, 32)\n",
            "Embedding(9742, 32)\n",
            "emb_0 torch.Size([10352, 32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-a6a13051db56>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0memb_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'propagate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Blog_LightGCN(MessagePassing):\n",
        "      def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "          super().__init__()\n",
        "          self.num_users, self.num_items = num_users, num_items\n",
        "          self.embedding_dim, self.K = embedding_dim, K\n",
        "          self.add_self_loops = add_self_loops\n",
        "          self.users_emb = nn.Embedding(\n",
        "              num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "          self.items_emb = nn.Embedding(\n",
        "              num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "          nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "          nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "      def forward(self, edge_index: SparseTensor):\n",
        "          # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "          edge_index_norm = gcn_norm(\n",
        "              edge_index, add_self_loops=self.add_self_loops)\n",
        "          emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "          embs = [emb_0]\n",
        "          emb_k = emb_0\n",
        "\n",
        "          # multi-scale diffusion\n",
        "          for i in range(self.K):\n",
        "              emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "              embs.append(emb_k)\n",
        "          embs = torch.stack(embs, dim=1)\n",
        "          emb_final = torch.mean(embs, dim=1) # E^K\n",
        "          users_emb_final, items_emb_final = torch.split(\n",
        "              emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "          # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "          return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "      def message(self, x_j: Tensor) -> Tensor:\n",
        "          return x_j\n",
        "\n",
        "      def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "          # computes \\tilde{A} @ x\n",
        "          return matmul(adj_t, x)"
      ],
      "metadata": {
        "id": "1Ra4mUWHiRIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixFactorization(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(MatrixFactorization, self).__init__()\n",
        "\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        # 임베딩 초기화\n",
        "        self.mf_user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
        "        self.mf_item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embedding = self.user_embedding(user_indices)\n",
        "        item_embedding = self.item_embedding(item_indices)\n",
        "\n",
        "        # 내적 연산으로 평점 예측\n",
        "        predictions = (user_embedding * item_embedding).sum(1)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "eJNr7GCPExLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터\n",
        "embedding_dim = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "\n",
        "num_users = blog_tet_edge_data[0][0].max().item()+1\n",
        "num_items = blog_tet_edge_data[0][1].max().item()+1\n",
        "# blog_tet_edge_data, blog_tet_sparse_data, user_mapping, item_mapping\n",
        "# print(blog_tet_edge_data[0][0])\n",
        "# print(blog_tet_edge_data[0][0].max().item())\n",
        "\n",
        "# print(blog_tet_edge_data[0][1])\n",
        "# print(blog_tet_edge_data[0][1].max().item())\n",
        "\n",
        "# 모델 초기화\n",
        "model = MatrixFactorization(num_users, num_items, embedding_dim).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "K7kh9HTqHz31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(blog_tet_edge_data[1][0]) #-- train\n",
        "print(blog_tet_edge_data[1][1]) #-- train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpxwLpr9Lx8a",
        "outputId": "69726c70-3d32-4f17-87e0-4ba1c6609892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 60, 124, 409,  ...,  65, 163, 427])\n",
            "tensor([1002, 4705,  820,  ..., 6422, 1044, 5309])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`blog_tet_edge_data[1][0]`는 사용자 노드의 인덱스를,  \n",
        "`blog_tet_edge_data[1][1]`는 아이템 노드의 인덱스를 나타내는 텐서(tensor)입니다.\n",
        "\n",
        "예를 들어, 출력값의 첫 번째 엔트리를 보면:\n",
        "\n",
        "- `blog_tet_edge_data[1][0][0]`의 값은 60\n",
        "- `blog_tet_edge_data[1][1][0]`의 값은 1002\n",
        "\n",
        "이는 60번 사용자가 1002번 아이템에 대한 상호작용(예: 레이팅, 구매, 클릭 등)을 가지고 있다는 것을 의미합니다.\n",
        "\n",
        "각각의 쌍(pair)은 사용자와 아이템 사이의 상호작용을 나타내며, 이러한 상호작용들은 추천 시스템이나 그래프 기반의 머신 러닝 태스크에서 중요한 정보를 제공합니다."
      ],
      "metadata": {
        "id": "2EJPm-2ZNO6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_indices =blog_tet_edge_data[1][0]\n",
        "item_indices = blog_tet_edge_data[1][1]"
      ],
      "metadata": {
        "id": "eAwhW1z-JeDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_indices)\n",
        "print(item_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk8ZcFNeKk1g",
        "outputId": "f1d03638-b447-4b4d-908b-a7cbdeda3ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 60, 124, 409,  ...,  65, 163, 427])\n",
            "tensor([1002, 4705,  820,  ..., 6422, 1044, 5309])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-- 손실함수 bpr\n",
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "XRjHpzqoYIOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}