### ABSTRACT

해당 논문은 비지도 학습 방식으로 자원을 할당하는 방법을 학습함으로써 전역 유틸리티 기능을 극대화하는 접근 방식을 설명한다. 저자들은 할당 대상 간의 상호 작용의 중요성을 고려하여 그래프 신경망(GNN)을 사용하여 거의 최적의 할당 정책에 대한 보상 구조를 학습할 것을 제안한다. 자원 제약을 완화함으로써 진화 알고리즘 대신 기울기 기반 최적화를 활용할 수 있다. 이 알고리즘의 동기는 제한된 초기 정보를 기반으로 많은 수의 은하 중에서 선택하여 우주의 구성을 최적으로 추론하는 것이 목표인 현대 천문학의 문제에서 비롯된다. 이 기술은 사회 과학 연구에서 고객 만족도 조사 및 자율 에이전트의 탐험 전략에 이르기까지 다양한 할당 문제에 적용될 가능성이 있다.

---

## 1. Resource Allocation for Observational Studies

### **기본 아이디어**

관측 연구에서는 여러 가지 행동이나 선택사항이 있지만, 제한된 리소스 (예: 시간, 돈, 장비 등) 때문에 모든 것을 한 번에 할 수 없다.

### **복잡한 상호작용**

단순히 가장 '좋은' 행동만을 선택하는 것이 아니라, 여러 행동이 어떻게 서로에게 영향을 미치는지도 고려해야 한다. 예를 들어, 하나의 관측이 다른 관측의 유용성을 높일 수 있다.

### **천문학 예시**

1. **서베이 (Survey)**: 이 방법은 하늘의 큰 부분을 '스캔'하는 것이다. 여기서는 특별히 어떤 별이나 행성을 대상으로 하지 않고, 많은 수의 천체를 대략적으로 살펴본다.
2. **대상 지향적 관측 (Target-Oriented Observation)**: 이 방법은 특정 별이나 행성, 혹은 다른 천체에 집중하여 더 자세한 데이터를 수집한다.

### **왜 리소스 할당이 중요한가?**

- 망원경과 같은 천문학 장비는 매우 비싸고, 사용할 수 있는 시간도 제한적이다.
- 따라서, 어떤 별이나 행성을 더 자세히 관찰할 것인지 결정해야 하는데, 이것이 바로 '리소스 할당' 문제이다.

### **예시**

- 천문학자들이 처음에는 '서베이'를 통해 여러 별들을 대략적으로 살펴본다.
- 그 다음, 이 '서베이'에서 흥미로운 별 몇 개를 발견했다고 가정
- 이제, 천문학자들은 이 흥미로운 별들 중에서 어떤 별을 더 자세히 관찰할 것인지 결정해야 한다.
- 이 결정은 여러 별들이 어떤 정보를 줄 수 있는지, 어떤 별이 더 중요한지 등 여러 요소를 고려해야 한다다.

간단히 말해, 천문학에서는 제한된 시간과 장비를 가장 잘 활용하기 위해 어떤 천체를 관찰할 것인지 신중하게 선택해야 합니다. 이러한 선택 과정이 바로 '리소스 할당' 문제에 해당한다.

### **왜 이게 중요한가?**

- 이러한 리소스 할당 문제는 단순한 최적화 문제를 넘어서 복잡한 상호작용과 다양한 응용 분야에서의 중요성을 갖는다. 예를 들어, 이 문제는 천문학뿐만 아니라 의료 연구, 환경 모니터링 등 다양한 분야에서도 적용될 수 있다.

간단히 말해서  제한된 리소스를 가장 효율적으로 사용하기 위해 어떤 '관측'이나 '행동'을 선택할 것인지에 대한 복잡한 문제를 다룬다. 이 문제는 단순히 가장 높은 '보상'을 주는 선택을 하는 것을 넘어서, 여러 선택 사항이 어떻게 서로 상호 작용하는지를 이해하는 것이 중요하다.

### Edge Computing에서의 **응용 방식:**

1. **작업 분배 (Task Allocation)**: Edge Computing 환경에서는 여러 엣지 노드가 있을 수 있다. 어떤 작업을 어떤 노드에서 처리할 것인지 결정
2. **데이터 스트리밍 (Data Streaming)**: 실시간으로 생성되는 대량의 데이터를 어떻게 처리할 것인지, 어떤 데이터를 중앙 서버로 전송할 것인지 등
3. **에너지 효율 (Energy Efficiency)**: 엣지 노드는 종종 배터리로 작동되므로, 에너지 효율적인 리소스 할당이 필요
4. **로드 밸런싱 (Load Balancing)**: 엣지 노드 간의 작업 부하를 균등하게 분배
5. **보안 및 프라이버시 (Security and Privacy)**: 어떤 데이터를 로컬에서 처리하고 어떤 데이터를 클라우드로 전송할 것인지 결정

### 그래프 신경망 (GNN)의 활용

- 엣지 컴퓨팅 네트워크의 복잡한 상호작용과 의존성을 모델링하기 위해 GNN을 사용할 수 있다.
- GNN은 각 엣지 노드의 상태와 이웃 노드와의 관계를 고려하여 더 효율적인 리소스 할당 전략을 만들 수 있다.

---

## 2. Context & Related Work

해당 섹션에서는 논문의 주요 기여와 관련 연구에 대해 다룬다. 이 섹션은 논문이 어떤 문제를 해결하려고 하는지, 그리고 이전에 어떤 연구가 이루어졌는지를 설명한다.

### 주요 기여

1. **점진적 문제 해결**: 논문에서는 GNN (Graph Neural Network)을 사용하여 리소스 할당 문제를 점진적으로 해결한다. 먼저, 어떤 샘플이 유틸리티를 극대화하는지 학습하고, 그 다음에 리소스 제한을 고려하여 조정한다.
2. **보상 함수의 학습**: 전통적인 접근법은 수동으로 정의된 보상 함수를 사용하지만, 이 논문에서는 두 번째 GNN과 시뮬레이션을 통해 보상 함수를 처음부터 학습한다.

### 1. 점진적 문제 해결

**예시: 스마트 홈**

- **상황**: 스마트 홈에는 에어컨, 냉장고, 스마트 TV, 보안 카메라 등 다양한 IoT 디바이스가 있다.
- **점진적 문제 해결**: 먼저, 각 디바이스가 어떤 상황에서 가장 중요한지를 학습한다. 예를 들어, 낮에는 에어컨이, 밤에는 보안 카메라가 중요할 수 있다.
- **적용**: 이 정보를 바탕으로, 낮에는 에어컨을 더 자주 체크하고, 밤에는 보안 카메라에 더 많은 리소스를 할당한다.

### 2. 보상 함수의 학습

**예시: 도시의 교통 관리**

- **상황**: 도시에는 여러 교통 신호등과 CCTV, 차량 감지 센서 등이 있다.
- **보상 함수의 학습**: 어떤 교통 신호등 설정이 교통 흐름을 가장 원활하게 만드는지 학습한다. 이를 위해, 각 설정에 대한 '보상'을 계산한다. 높은 보상은 교통이 원활하게 흐르는 것을 의미한다.
- **적용**: 이 보상이 높은 설정을 사용하여 실제 교통 신호등을 조절한다.

### 3. 연계된 접근법

**예시: 스마트 팩토리**

- **상황**: 스마트 팩토리에는 여러 제조 기계와 센서, 로봇 팔 등이 있다.
- **점진적 문제 해결**: 먼저, 어떤 기계나 로봇 팔이 가장 중요한 작업을 하는지 학습한다.
- **보상 함수의 학습**: 그 다음, 이 중요한 기계나 로봇 팔에 작업을 할당할 때 어떤 순서가 가장 효율적인지 학습한다.
- **적용**: 이 두 가지 정보를 결합하여, 중요한 기계나 로봇 팔에 더 많은 작업을 할당하고, 그 작업을 가장 효율적인 순서로 실행한다.

이렇게 각 접근법은 별개로도 유용하게 사용될 수 있고, 둘을 결합하여 더 효율적인 리소스 할당이 가능하다.

### **관련 연구**

- 논문은 이전에 이루어진 여러 연구와 비교하며 자신의 방법의 우수성을 강조한다. 예를 들어, 이전 연구에서는 수동으로 정의된 보상 함수나 휴리스틱을 사용했지만, 이 논문에서는 이러한 한계를 극복하고 있다.

이러한 내용을 통해 논문은 리소스 할당 문제에 대한 새로운 접근법과 해결책을 제시하고 있다. 이는 다양한 분야에서, 특히 제한된 리소스를 효율적으로 사용해야 하는 분야에서 유용하게 적용될 수 있다.

---

## 3. Methodology & Experimental Protocol

### **방법론과 실험 프로토콜**

해당 섹션에서는 논문의 연구 방법론과 실험 프로토콜에 대해 설명한다. 이 섹션은 크게 세 부분으로 나뉜다.

- 동기부여
- GNN 변형 및 학습 알고리즘
- 실험 설계 및 성능 지표

### **1. 동기부여 (Motivation)**

- **실세계 문제**: 논문은 천문학 연구에서의 실제 문제를 중심으로 설명한다. 이 문제는 대규모 천문학 조사에서 수십억 개의 거리 떨어진 은하를 측정하는 것이다.

**예시:**

- **실세계 문제**: 천문학자들이 은하계의 구성과 우주의 구조를 더 잘 이해하기 위해, 어떤 은하계를 관측할지 결정해야 한다.
- **논문의 접근법**: 이 논문에서는 GNN을 사용하여 어떤 은하계가 가장 정보가 풍부한지 판단하고, 그에 따라 관측 리소스를 할당한다.

### 2. GNN 변형 및 학습 알고리즘 (GNN Variant & Training Algorithm)

- **상세한 정의**: 논문에서는 사용하는 GNN의 변형과 그에 대한 하이퍼파라미터, 학습 알고리즘을 상세하게 설명한다.

**예시:**

- **GNN 변형**: 논문에서는 기존 GNN을 변형하여, 은하계의 위치와 거리, 질량 등을 고려할 수 있게 한다.
- **학습 알고리즘**: 논문에서는 이 변형된 GNN을 효과적으로 학습시키기 위한 알고리즘을 제시한다.

### 3. 실험 설계 및 성공 지표 (Experimental Design & Success Metrics)

- **실험 방법과 지표**: 논문에서는 실험을 어떻게 수행할지, 그리고 실험의 성공을 어떻게 측정할지 설명한다.

**예시:**

- **실험 방법**: 논문에서는 실제 천문학 데이터를 사용하여 실험을 진행한다.
- **성공 지표**: 논문에서는 얼마나 많은 은하계의 정보를 정확하게 추출할 수 있었는지를 성공 지표로 사용한다.

이 섹션을 통해 논문이 어떤 실세계 문제를 해결하려고 하는지, 그리고 그 문제를 해결하기 위해 어떤 방법론과 실험 설계를 사용하는지를 이해할 수 있다.

### 예시: 스마트 홈 네트워크의 데이터 전송 최적화

### 1. 환경 설정 (Environment Setup)

- **노드**: 스마트 냉장고, 스마트 TV, 스마트 스피커 등
- **엣지**: 각 노드간의 데이터 전송 경로 (Wi-Fi, 블루투스 등)
- **상태 (State)**: 각 노드의 현재 상태 (온도, 볼륨 등)과 네트워크의 전반적인 상태 (전송 지연, 에러율 등)
- **행동 (Action)**: 데이터를 어떤 경로로 전송할 것인지, 어떤 노드에 우선순위를 둘 것인지 등
- **보상 (Reward)**: 데이터 전송이 얼마나 효율적으로 이루어졌는지 (지연 시간 감소, 에러율 감소 등)

### 2. 초기화 (Initialization)

- GNN의 파라미터와 각 노드의 초기 상태를 설정합니다.

### 3. 강화학습을 통한 학습

1. **에피소드 시작 (Start Episode)**
    - 스마트 홈 네트워크의 초기 상태로 시작합니다.
2. **행동 선택 (Select Action)**
    - GNN은 현재 상태를 기반으로 행동을 선택합니다. 예를 들어, 스마트 스피커가 스마트 냉장고에 데이터를 전송할 때 어떤 경로를 선택할지 결정합니다.
3. **환경과 상호작용 (Interact with Environment)**
    - 선택한 행동을 실행한 후, 환경 (스마트 홈 네트워크)에서 어떤 결과가 발생했는지 관찰합니다. 예를 들어, 데이터 전송이 얼마나 빨리 이루어졌는지, 에러가 발생했는지 등을 확인합니다.
4. **보상 계산 (Calculate Reward)**
    - 행동의 결과를 바탕으로 보상을 계산합니다. 예를 들어, 데이터 전송이 빠르게 이루어졌다면 높은 보상을, 에러가 발생했다면 낮은 보상을 받습니다.
5. **업데이트 (Update)**
    - 보상과 결과를 사용하여 GNN의 파라미터를 업데이트합니다. 이는 보통 역전파 (Backpropagation) 알고리즘을 사용합니다.
6. **에피소드 반복 (Repeat Episode)**
    - 여러 번의 에피소드를 통해 GNN은 점점 더 효율적인 데이터 전송 방법을 학습합니다.

### 4. 평가 및 적용 (Evaluation and Deployment)

- 학습이 완료된 GNN을 실제 스마트 홈 네트워크에 적용하여 성능을 평가합니다.

이렇게 GNN은 강화학습을 통해 스마트 홈 네트워크에서 데이터 전송을 최적화하는 방법을 학습합니다. 학습 과정에서는 여러 에피소드를 거쳐서 점점 더 좋은 행동을 선택하게 되고, 이를 통해 전반적인

네트워크 통신 성능을 향상시킵니다.

<img width="785" alt="1" src="https://github.com/junyong1111/AlphaProject-GNN/assets/79856225/b363539c-9e07-4e30-9ca1-f736f791cf18">


<aside>
💡 **에지 디바이스 간의 리소스 할당을 최적화하여 데이터의 효율적인 처리 및 분석을 수행하는 것이 목표**

스마트 시티 환경에 배치된 에지 장치 네트워크가 있다고 가정하자. 이 장치들은 온도, 습도, 공기 질, 교통 패턴 등 다양한 센서 데이터를 수집하며, 네트워크 가장자리에서 수집된 데이터에 대한 실시간 분석을 수행할 수 있도록 계산 자원을 효과적으로 할당하는 것이 목적이다.

이 시나리오에서 리소스 할당을 위해 알고리즘 1 사용:

**1. 매개 변수 초기화**: GNN(Graph Neural Networks)에서 사용할 매개 변수 σ1과 σ2 두 세트를 초기화하는 것으로 시작한다.

**2. 시뮬레이션 데이터**:  날씨 조건이나 하루 중 시간과 같은 일부 환경 요인을 기반으로 스마트 시티 환경 내의 다양한 위치에서 센서 판독값을 시뮬레이션한다.

**3. 이전 상태를 시뮬레이션할 노이즈 추가**: 각 위치의 센서 판독값에 대한 초기 정보의 측정 오류 또는 불확실성을 설명하기 위해 무작위 노이즈 값을 추가하여 이전 상태(v'i)를 시뮬레이션한

**4. GNN1을 이용한 자원 할당 최적화** : GNN1을 이용하여 알고리즘은 각각의 시뮬레이션된 이전 상태(v'i)를 기반으로 각 위치에 **얼마나 많은 계산 자원을 할당해야 하는지를 결정**한다. 예를 들어, 잠재적인 화재 위험을 나타내는 온도 수준에 급격한 변화가 감지되는 경우 더 높은 할당이 제공될 수 있다.

**5.GNN2를 이용한 파라미터 추정** : **GNN2는 자원을 최적으로 할당**한 후, 서로 다른 위치에서 발생하는 특정 사건과 관련된 중요한 파라미터를 추정하는데 도움이 되며, 예를 들어 최적의 자원 할당 후 공기질 센서의 측정값을 이용하여 오염도를 추정할 수 있다.

**6.합산손실 계산**:합산손실함수는 다음의 세 가지 요소를 고려한다:

- 추정 파라미터(θ_hat)와 참 파라미터(θ)의 차이
- 할당된 총 리소스(H)의 편차
- 희소 패널티(알파)

**7.Update Parameters**: 마지막으로, 파라미터 σ1과 σ2는 이들 결합된 손실을 기반으로 기울기 강하 최적화를 사용하여 업데이트되며, 이는 Edge Computing 네트워크에서 자원 할당 및 추정 프로세스의 향후 반복을 개선하는 데 도움이 된다.

</aside>

---

## 5. CONCLUSION

### 결론

### 주요 발견

1. **목표 달성**: 제시된 비지도 학습 GNN 할당 알고리즘은 전역 환경 변수을 예측하면서 동시에 제한된 리소스를 최적으로 할당하고 그 결과를 분석하는 목표를 달성했다.
2. **성능**: 이 알고리즘은 더 전통적인 할당 전략보다 성능이 우수하다.
3. **변수 환경에서의 학습**: 학습은 알려지지 않은 환경에서 이루어지며, 그 환경은 여러 변수로 설명된다. 이는 천문학에서 일반적으로 사용되는 고정된 및 알려진 환경을 가정하는 방법과는 다르다.
4. **비균일 선택**: 할당은 명확하게 비균일한 은하 선택으로 이루어진다. 전통적인 분석 방법은 이를 명시적으로 수정해야 하지만, 제시된 GNN2는 자동으로 이를 교정한다.
5. **다른 분야에서의 응용 가능성**: 이 연구는 관측 과학의 다른 응용 분야에서도 유용하게 적용될 수 있을 것으로 제안된다.

### 해석

- **비지도 학습 GNN 할당 알고리즘**: 이 알고리즘은 지도학습이 아닌 비지도 학습을 사용하여 리소스를 할당합니다. 이는 알고리즘이 스스로 최적의 리소스 할당 방법을 학습한다는 것을 의미합니다.
- **전역 환경 변수**: 이 변수는 천문학적 또는 기타 과학적 연구에서 중요한 역할을 하는 것으로 보입니다. 알고리즘이 이 변수를 예측할 수 있다는 것은 매우 중요한 발견입니다.
- **비균일 선택의 자동 교정**: 전통적인 방법에서는 데이터의 비균일성을 수동으로 교정해야 하지만, 이 GNN 알고리즘은 그것을 자동으로 처리합니다.
- **다양한 응용 분야**: 이 알고리즘은 천문학 외에도 다른 관측 과학 분야에서도 유용하게 적용될 수 있다.